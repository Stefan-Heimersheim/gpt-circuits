HOW TO USE THE ATTRIBUTION CODE:

GPT-2
0) 
Do the usual setup, run the following if you haven't already
    pip install -r requirements.txt
    python -m data.fineweb_edu_10b.prepare (This takes like an hour, you need 100GB of disk space, add that on runpod before you run)
1)
Download the models
    hf download davidquarel/sc.mlpblock.gpt2.k32.x32 --local-dir checkpoints/sc.mlpblock.gpt2.k32.x32
    hf download davidquarel/jln.mlpblock.gpt2-sparse-0.0ep00 --local-dir checkpoints/jln.mlpblock.gpt2-sparse-0.0ep00
    hf download davidquarel/jln.mlpblock.gpt2-sparse-1.0e-08 --local-dir checkpoints/jln.mlpblock.gpt2-sparse-1.0e-08
    hf download davidquarel/jln.mlpblock.gpt2-sparse-5.0e-01 --local-dir checkpoints/jln.mlpblock.gpt2-sparse-5.0e-01


1) 
commands.txt has a list of commands like
    CUDA_VISIBLE_DEVICES=0 python Andy/compute_attributions.py --load_from=checkpoints/jln.mlpblock.gpt2-sparse-0.0ep00 --save_to=Andy/data --data_dir=data/fineweb_edu_10b --save_name=jln.mlpblock.gpt2-sparse-0.0ep00 --num_batches=8 --batch_size=12 --steps=1 --attribution_method=ig --layers=1

Match these to whatever your compute is, and what layer you want to run. layers can be a list











SHAKESPEARE
0) Do the usual setup, run the following if you haven't already
pip install -r requirements.txt
python -m data.shakespeare.prepare

1) Open Andy/model_download. This should be the only file you need to open. Put in whatever you want so that:
    model_names is a list of strings pointing to models in huggingface, the models you want to run attributions on
    local_dirs is a list (of the same size) of strings with the name of folders where you want to save the model
    save_names is a list (of the same size) of strings that you want the model attribution to be saved with
    download = True

2) Run model_download. It should save the models to different folders (usually in checkpoints, but you get to control this). It will also make a folder gpt-circuits/ called 'commands.txt'

3) in the terminal run 'bash < commands.txt'
    This should fill Andy/data with safetensor files with the names you listed in save_names

4) In terminal run 'huggingface-cli login' Enter a login code when prompted. Say n if it asks about a github token
    I will share my huggingface login in Slack.

5) Reopen Andy/model_download. Set download = False, save, and run 'python Andy/model_download' is the terminal

6) You are all done!

Points of concern: 
Many of my files begin with 
    import sys
    sys.path.append('/workspace/gpt-circuits')
I did this because I wans't sure how to otherwise make it easy to import other code I wrote. 
You might need to adjust this for the import statements to workspace

I have encountered cross transformer block models that do not have a SAE after the 4th layer. This will cause the code to fail. 
Fast fix: go to line 68 in attributor.py and change it to the commented version 'for i in range(layers-1):'



